{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7a73f35590>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import TransformedRoboEireanData, RoboEireanDataWithEncoder\n",
    "import utils\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "import pytorch_lightning as pl\n",
    "from models import MultiClassJetNet\n",
    "import torchvision.transforms as T\n",
    "torch.manual_seed(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoboEirean Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Default scalings for the default boxes determined by k-means clustering\n",
    "# default_box_scalings = torch.tensor(\n",
    "#     [\n",
    "#         [0.06549374, 0.12928654],\n",
    "#         [0.11965626, 0.26605093],\n",
    "#         [0.20708716, 0.38876095],\n",
    "#         [0.31018215, 0.47485098],\n",
    "#         [0.415882, 0.8048184],\n",
    "#         [0.7293086, 0.8216225],\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "# classes = [\"robot\"]\n",
    "# encoder = utils.Encoder(default_box_scalings, [\"robot\"])\n",
    "# transformed_train_data = TransformedRoboEireanData(\n",
    "#     os.path.join(\"data\", \"transformed\", \"train\"), encoder\n",
    "# )\n",
    "# transformed_val_data = TransformedRoboEireanData(\n",
    "#     os.path.join(\n",
    "#         \"data\",\n",
    "#         \"transformed\",\n",
    "#         \"val\",\n",
    "#     ),\n",
    "#     encoder,\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoboEireann Augmented Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default scalings for the default boxes determined by k-means clustering\n",
    "default_box_scalings = torch.tensor(\n",
    "    [\n",
    "        [0.06549374, 0.12928654],\n",
    "        [0.11965626, 0.26605093],\n",
    "        [0.20708716, 0.38876095],\n",
    "        [0.31018215, 0.47485098],\n",
    "        [0.415882, 0.8048184],\n",
    "        [0.7293086, 0.8216225],\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "classes = [\"robot\"]\n",
    "encoder = utils.Encoder(default_box_scalings, [\"robot\"])\n",
    "\n",
    "image_transforms = T.Compose(\n",
    "            [\n",
    "                T.Grayscale(),\n",
    "                T.PILToTensor(),\n",
    "                T.ConvertImageDtype(torch.float32),\n",
    "                T.Resize((60, 80)),\n",
    "            ]\n",
    "        )\n",
    "bounding_box_transforms = T.Compose([])\n",
    "\n",
    "raw_train_data = RoboEireanDataWithEncoder(os.path.join(\"data\", \"raw\", \"train\"),\n",
    "                                           encoder,\n",
    "                                           [\"robot\"], image_transforms=image_transforms, bounding_box_transforms=bounding_box_transforms)\n",
    "\n",
    "raw_val_data = RoboEireanDataWithEncoder(os.path.join(\"data\", \"raw\", \"val\"),\n",
    "                                           encoder,\n",
    "                                           [\"robot\"], image_transforms=image_transforms, bounding_box_transforms=bounding_box_transforms)\n",
    "train_loader = DataLoader(\n",
    "    raw_train_data, batch_size=32, shuffle=True, num_workers=1\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    raw_val_data, batch_size=32, shuffle=False, num_workers=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO Synthetic Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_box_scalings = torch.tensor(\n",
    "#     [\n",
    "#        [ 49.858948,  42.32408 ],\n",
    "#        [ 79.69058 ,  96.98148 ],\n",
    "#        [162.30188 , 125.641266],\n",
    "#        [229.88889 , 248.09436 ],\n",
    "#        [251.65385 , 434.61536 ],\n",
    "#        [626.4     , 461.2     ]\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# image_transforms = T.Compose(\n",
    "#             [\n",
    "#                 T.Grayscale(),\n",
    "#                 T.PILToTensor(),\n",
    "#                 T.ConvertImageDtype(torch.float32),\n",
    "#                 T.Resize((60, 80)),\n",
    "#             ]\n",
    "#         )\n",
    "# bounding_box_transforms = T.Compose([])\n",
    "\n",
    "# raw_train_data = RoboEireanDataWithEncoder(os.path.join(\"data\", \"coco_ball_nao\", \"train\"),\n",
    "#                                            encoder,\n",
    "#                                            [\"robot\"], image_transforms=image_transforms, bounding_box_transforms=bounding_box_transforms)\n",
    "\n",
    "# raw_val_data = RoboEireanDataWithEncoder(os.path.join(\"data\", \"coco_ball_nao\", \"val\"),\n",
    "#                                            encoder,\n",
    "#                                            [\"robot\"], image_transforms=image_transforms, bounding_box_transforms=bounding_box_transforms)\n",
    "# train_loader = DataLoader(\n",
    "#     raw_train_data, batch_size=32, shuffle=True, num_workers=1\n",
    "# )\n",
    "# val_loader = DataLoader(\n",
    "#     raw_val_data, batch_size=32, shuffle=False, num_workers=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m learning_rate \u001b[39m=\u001b[39m \u001b[39m2e-3\u001b[39m\n\u001b[0;32m----> 2\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m      3\u001b[0m     raw_train_data, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m val_loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m      6\u001b[0m     raw_val_data, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m pl_model \u001b[39m=\u001b[39m MultiClassJetNet(\u001b[39mlen\u001b[39m(classes), default_box_scalings\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), learning_rate)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "learning_rate = 2e-3\n",
    "train_loader = DataLoader(\n",
    "    raw_train_data, batch_size=32, shuffle=True, num_workers=0\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    raw_val_data, batch_size=32, shuffle=True, num_workers=0\n",
    ")\n",
    "\n",
    "pl_model = MultiClassJetNet(len(classes), default_box_scalings.size(0), learning_rate)\n",
    "trainer = pl.Trainer(\n",
    "    limit_predict_batches=100, max_epochs=200, callbacks=[RichProgressBar()]\n",
    ")\n",
    "trainer.fit(model=pl_model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_model.eval()\n",
    "batch = next(iter(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predictions_single_batch = pl_model(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(model=pl_model, dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(model=pl_model, dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from visualize import draw_model_output, image_grid\n",
    "# import utils\n",
    "\n",
    "\n",
    "# grid_size = 1000\n",
    "# image_list = []\n",
    "# for i in range(grid_size * grid_size):\n",
    "#     image, encoded_bounding_boxes, target_masks, encoded_target_classes = raw_train_data[i]\n",
    "#     predicted_boxes, predicted_class_logits = pl_model(image.unsqueeze(0))\n",
    "#     predicted_classes = utils.calculate_predicted_classes(predicted_class_logits).squeeze()\n",
    "#     print(predicted_classes)\n",
    "#     decoded_boxes = encoder.decode_model_output(predicted_boxes, predicted_classes)\n",
    "#     image_list.append(\n",
    "#         draw_model_output(\n",
    "#             image,\n",
    "#             decoded_boxes,\n",
    "#             predicted_classes,\n",
    "#             torch.tensor([0, 1]),\n",
    "#         )\n",
    "#     )\n",
    "# image_grid(image_list, grid_size, grid_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4b33f3bd3006839683caa3a05bbc4ebc251421a0b5188a4af3ca802ec5d8974"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
