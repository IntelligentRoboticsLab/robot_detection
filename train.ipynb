{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4899f59b90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from object_detection_data import Encoder, TransformedDataset\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "import pytorch_lightning as pl\n",
    "from object_detection_models import MultiClassJetNet\n",
    "\n",
    "torch.manual_seed(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_scalings = torch.tensor(\n",
    "    [[0.25, 0.25], [0.2, 0.2], [0.125, 0.125], [0.125 / 2, 0.125 / 2], [0.125 / 4, 0.125 / 4]])\n",
    "feature_map_size = (8, 10)\n",
    "num_classes = 4\n",
    "encoder = Encoder(default_scalings, feature_map_size, num_classes)\n",
    "transformed_train_data = TransformedDataset('data/train', encoder)\n",
    "transformed_val_data = TransformedDataset('data/val', encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "   | Name                   | Type               | Params\n",
      "---------------------------------------------------------------\n",
      "0  | accuracy               | MulticlassAccuracy | 0     \n",
      "1  | batch_normalization_1  | BatchNorm2d        | 2     \n",
      "2  | conv2d_1               | Conv2d             | 160   \n",
      "3  | batch_normalization_2  | BatchNorm2d        | 32    \n",
      "4  | depthwise_conv2d_1     | Conv2d             | 144   \n",
      "5  | conv2d_2               | Conv2d             | 408   \n",
      "6  | batch_normalization_3  | BatchNorm2d        | 48    \n",
      "7  | depthwise_conv2d_2     | Conv2d             | 216   \n",
      "8  | conv2d_3               | Conv2d             | 400   \n",
      "9  | batch_normalization_4  | BatchNorm2d        | 32    \n",
      "10 | depthwise_conv2d_3     | Conv2d             | 144   \n",
      "11 | conv2d_4               | Conv2d             | 340   \n",
      "12 | batch_normalization_5  | BatchNorm2d        | 40    \n",
      "13 | depthwise_conv2d_4     | Conv2d             | 180   \n",
      "14 | conv2d_5               | Conv2d             | 420   \n",
      "15 | batch_normalization_6  | BatchNorm2d        | 40    \n",
      "16 | depthwise_conv2d_5     | Conv2d             | 180   \n",
      "17 | conv2d_6               | Conv2d             | 420   \n",
      "18 | batch_normalization_7  | BatchNorm2d        | 40    \n",
      "19 | depthwise_conv2d_6     | Conv2d             | 180   \n",
      "20 | conv2d_7               | Conv2d             | 420   \n",
      "21 | batch_normalization_8  | BatchNorm2d        | 40    \n",
      "22 | depthwise_conv2d_7     | Conv2d             | 180   \n",
      "23 | conv2d_8               | Conv2d             | 420   \n",
      "24 | batch_normalization_9  | BatchNorm2d        | 40    \n",
      "25 | depthwise_conv2d_8     | Conv2d             | 180   \n",
      "26 | conv2d_9               | Conv2d             | 504   \n",
      "27 | batch_normalization_10 | BatchNorm2d        | 48    \n",
      "28 | conv2d_10              | Conv2d             | 5.2 K \n",
      "29 | batch_normalization_11 | BatchNorm2d        | 48    \n",
      "30 | conv2d_11              | Conv2d             | 5.2 K \n",
      "31 | batch_normalization_12 | BatchNorm2d        | 48    \n",
      "32 | conv2d_12              | Conv2d             | 5.2 K \n",
      "33 | batch_normalization_13 | BatchNorm2d        | 48    \n",
      "34 | conv2d_13              | Conv2d             | 5.2 K \n",
      "35 | conv2d_14              | Conv2d             | 1.1 K \n",
      "---------------------------------------------------------------\n",
      "27.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.4 K    Total params\n",
      "0.109     Total estimated model params size (MB)\n",
      "2023-02-09 14:43:06.727149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-09 14:43:06.871442: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-09 14:43:07.555361: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-09 14:43:07.555422: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-09 14:43:07.555428: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebcb441b6404680b18209597534a87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860aca166b19435a90c71a33603c8bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06bed73f8af45148c8f53e4da405869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/hulks/ml/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(transformed_train_data, batch_size=4,\n",
    "                          shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(transformed_val_data, batch_size=4,\n",
    "                        shuffle=False, num_workers=4)\n",
    "\n",
    "pl_model = MultiClassJetNet(num_classes, len(default_scalings))\n",
    "trainer = pl.Trainer(limit_predict_batches=100,\n",
    "                     max_epochs=20)\n",
    "trainer.fit(model=pl_model, train_dataloaders=train_loader,\n",
    "            val_dataloaders=val_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 19 2022, 17:35:49) [GCC 12.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8179af3a6648109ce06e2d9f5db23fa843e75289adf6dc335b42c828d3bf7f76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
