{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Encoder\n",
    "import utils\n",
    "import torch\n",
    "from datasets import RoboEireanDataModule\n",
    "import lightning.pytorch as pl\n",
    "from PIL import ImageDraw, Image\n",
    "\n",
    "from models import JetNet, SingleShotDetector, ObjectDetectionTask\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from visualize import draw_bounding_box"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model checkpoint and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-1\n",
    "ALPHA = 2.0\n",
    "NUM_CLASSES = 1\n",
    "DEFAULT_SCALINGS = torch.tensor(\n",
    "    [\n",
    "        [0.06549374, 0.12928654],\n",
    "        [0.11965626, 0.26605093],\n",
    "        [0.20708716, 0.38876095],\n",
    "        [0.31018215, 0.47485098],\n",
    "        [0.415882, 0.8048184],\n",
    "        [0.7293086, 0.8216225],\n",
    "    ]\n",
    ")\n",
    "encoder = Encoder(DEFAULT_SCALINGS, NUM_CLASSES)\n",
    "model = JetNet(NUM_CLASSES, DEFAULT_SCALINGS.shape[0])\n",
    "loss = SingleShotDetector(ALPHA)\n",
    "\n",
    "version = 1\n",
    "checkpoint_folder = f\"new_logs/lightning_logs/version_{version}/checkpoints/\"\n",
    "checkpoint_path = \"epoch=1-step=56.ckpt\"\n",
    "\n",
    "\n",
    "checkpoint_path = checkpoint_folder + checkpoint_path\n",
    "loaded_model = ObjectDetectionTask.load_from_checkpoint(\n",
    "    checkpoint_path=checkpoint_path, \n",
    "    model=model, \n",
    "    loss=loss, \n",
    "    encoder=encoder, \n",
    "    learning_rate=LEARNING_RATE)\n",
    "loaded_model\n",
    "\n",
    "# get the data we want to visualize and predict on\n",
    "data_module = RoboEireanDataModule(\"data/raw/\", encoder, 128)\n",
    "data_module.setup(\"fit\")  # TODO: inspect different stages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load single image prediction from validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, _, target_bb, target_class = next(iter(data_module.val_dataloader()))\n",
    "predicted_boxes, predicted_logits = loaded_model.model(image)\n",
    "predicted_classes, softmax  = utils.calculate_predicted_classes(predicted_logits)\n",
    "decoded_boxes = encoder.decode(predicted_boxes).squeeze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate over 50 batches and check for positive predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 730, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 728, in rmtree\n",
      "    os.rmdir(path)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-obazcqxe'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 730, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 728, in rmtree\n",
      "    os.rmdir(path)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-3ejqpfkb'\n"
     ]
    }
   ],
   "source": [
    "skip = 10\n",
    "for i in range(50):\n",
    "    image, _, target_bb, target_class = next(iter(data_module.val_dataloader()))\n",
    "    \n",
    "    predicted_boxes, predicted_logits = loaded_model.model(image)\n",
    "\n",
    "    predicted_classes, softmax = utils.calculate_predicted_classes(predicted_logits)\n",
    "    sorted_softmax = torch.sort(softmax[0][:,1], descending=True).indices\n",
    "\n",
    "    decoded_boxes = encoder.decode(predicted_boxes).squeeze()\n",
    "\n",
    "\n",
    "    for i in range(128):\n",
    "\n",
    "        if 1 in predicted_classes[i]:\n",
    "            print(predicted_classes)\n",
    "\n",
    "            # object_boxes = decoded_boxes[i][predicted_classes[i] > 0]\n",
    "            # if len(object_boxes) > 0:\n",
    "            #     print(object_boxes)\n",
    "            # else:\n",
    "            #     print(\"No positive found\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for duplicate prediction logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_count = 0\n",
    "\n",
    "for i in range(127):\n",
    "    for j in range(i + 1, 128):\n",
    "        print(predicted_logits[i])\n",
    "        print(predicted_logits[j])\n",
    "        if not torch.all(predicted_logits[i].eq(predicted_logits[j])):\n",
    "\n",
    "            equal_count += 1\n",
    "\n",
    "print(f'{equal_count} of the 128 predictions are not equal to each other')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 28\n",
    "fig = plt.figure(figsize=(9, 13))\n",
    "\n",
    "image_list = []\n",
    "for i in range(128):\n",
    "    image_pil = T.ToPILImage()(image[i][0]).convert(\"RGBA\")\n",
    "    draw = ImageDraw.Draw(image_pil)\n",
    "    print(predicted_classes[0])\n",
    "    object_boxes = decoded_boxes[i][predicted_classes[0] > 0]\n",
    "    draw = draw_bounding_box(image_pil, object_boxes)\n",
    "    plt.imshow(draw)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
